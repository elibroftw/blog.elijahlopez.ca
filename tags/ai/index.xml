<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ai on ELL Blog</title>
    <link>https://blog.elijahlopez.ca/tags/ai/</link>
    <description>ELL Blog (Ai)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 05 May 2025 15:33:20 -0400</lastBuildDate>
    
    <atom:link href="https://blog.elijahlopez.ca/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>AI Coding Leaderboard</title>
      <link>https://blog.elijahlopez.ca/posts/ai-coding-leaderboard/</link>
      <pubDate>Mon, 05 May 2025 15:33:20 -0400</pubDate>
      
      <guid>https://blog.elijahlopez.ca/posts/ai-coding-leaderboard/</guid>
      <description>&lt;p&gt;DEPRECATED: &lt;a href=&#34;https://aider.chat/docs/leaderboards/&#34;&gt;Aider Polyglot&lt;/a&gt; is multi-lingual compared to SWE-bench verified and that does not require me to make use of my own aggregated leaderboard. I will still try my best to maintain this post, but just letting you know I suggest using Aider Polyglot going forward for which model to use for pair programming.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aider.chat/2024/12/21/polyglot.html#the-polyglot-benchmark&#34;&gt;Aider polyglot&lt;/a&gt;: Based on the 225 most difficult &lt;a href=&#34;https://exercism.org/&#34;&gt;Exercism&lt;/a&gt; coding problems in the following languages: C++, Go, Java, JavaScript, Python and Rust. See &lt;a href=&#34;https://aider.chat/docs/leaderboards/&#34;&gt;Aider polyglot coding leaderboard&lt;/a&gt;. The problem I see is that models can just train on the solutions and game this leaderboard versus LiveCodeBench which is free of contaminations.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openai.com/index/introducing-swe-bench-verified/&#34;&gt;SWE-bench verified&lt;/a&gt; (August 13, 2024). A subset of 500 Python-exclusive tasks from the full 2000 which have been verified by humans as solvable. This is the defacto way to evaluate AI models as almost almost all models will report their scores for this benchmark. The unofficial &lt;a href=&#34;https://www.swebench.com/#verified&#34;&gt;leaderboard&lt;/a&gt; includes SWE copilot tool. The problem is that it doesn&amp;rsquo;t include self-reported results unlike my leaderboard.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://codeforces.com/&#34;&gt;Codeforces&lt;/a&gt;: the elo represents how good the AI model is at competitive programming tasks. There is no leaderboard since most AI models will self-report or benchmark other models&lt;/li&gt;
&lt;li&gt;The problem with EvalPlus is that it doesn&amp;rsquo;t include bleeding edge models, it&amp;rsquo;s basically almost solved, and not many new models even report their scores anymore.&lt;/li&gt;
&lt;li&gt;I don&amp;rsquo;t like LiveCodeBench because it&amp;rsquo;s not useful for comparing different models released at different times due to (1) every-updating problem set (2) not continuously testing all frontier models. If a benchmark score has an expiry date, then referencing it is really bad for a leaderboard. It&amp;rsquo;s good for relative performance in papers however then you have to read the fine print to ensure the authors retested the models they compared their new model against. See how complicated that is? Then you&amp;rsquo;d have to compile your own leaderboard because can you really trust others to do it right? No you can&amp;rsquo;t! I may include some sort of LiveCodeBench relative ranking in the future.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Future: Replace AIder Polyglot with SWE-bench Multilingual&lt;/p&gt;
&lt;p&gt;Ideally, the best programming tool would be implemented as follows, given the release of grok-1-fast:&lt;/p&gt;
&lt;p&gt;An Architecture &amp;lt;-&amp;gt; Programmer workflow where an agent is in charge of responding to questions that the coder agent has. The thinker will be the one to plan out the project and break it into chunks for the programer to implement.&lt;/p&gt;
&lt;h3 id=&#34;leaderboard&#34; &gt;Leaderboard
&lt;span&gt;
    &lt;a href=&#34;#leaderboard&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Model / Product&lt;/th&gt;
          &lt;th&gt;Company&lt;/th&gt;
          &lt;th&gt;Tier&lt;/th&gt;
          &lt;th&gt;Aider Polyglot&lt;/th&gt;
          &lt;th&gt;SWE-bench verified&lt;/th&gt;
          &lt;th&gt;Codeforces&lt;/th&gt;
          &lt;th&gt;Date Available&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Grok 4 Fast&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;xAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude Sonnet 4.5 &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;77.2%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;GPT-5-Codex&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;74.5%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;GPT-5&lt;sup id=&#34;fnref1:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;88%&lt;/td&gt;
          &lt;td&gt;72.8%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Codex-1&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;72.1%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;May-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude Opus 4.1&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;74.5%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Aug-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude Sonnet 4 &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;72.7%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;May-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude Opus 4&lt;sup id=&#34;fnref1:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;72.5%&lt;/td&gt;
          &lt;td&gt;72.5%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;May-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Grok Code Fast 1&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;xAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;70.8%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Aug-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude Sonnet 3.7 (Custom Scaffold)&lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;70.3%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Feb-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemini 2.5 Pro&lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;67.2%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;May-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen 3 Coder 480B&lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;61.8%&lt;/td&gt;
          &lt;td&gt;69.6%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Jul-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;o3-pro&lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;84.9%&lt;/td&gt;
          &lt;td&gt;69.0%&lt;/td&gt;
          &lt;td&gt;2748&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;o3&lt;sup id=&#34;fnref1:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;79.6%&lt;/td&gt;
          &lt;td&gt;69.1%&lt;/td&gt;
          &lt;td&gt;2706&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen 3 Max&lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;69.6%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek-V3.1-Terminus&lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;76.1%&lt;/td&gt;
          &lt;td&gt;68.4%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;o4-mini&lt;sup id=&#34;fnref2:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;72.0%&lt;/td&gt;
          &lt;td&gt;68.1%&lt;/td&gt;
          &lt;td&gt;2719&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek-V3.2-Exp&lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;74.5%&lt;/td&gt;
          &lt;td&gt;67.8%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;GLM-4.6&lt;sup id=&#34;fnref:15&#34;&gt;&lt;a href=&#34;#fn:15&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;15&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Z AI&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;68%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek-V3.1&lt;sup id=&#34;fnref:16&#34;&gt;&lt;a href=&#34;#fn:16&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;16&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;66.0%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Aug-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Code World Model&lt;sup id=&#34;fnref:17&#34;&gt;&lt;a href=&#34;#fn:17&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;17&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Meta&lt;/td&gt;
          &lt;td&gt;OIII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;65.8 %&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Kimi-K2-Instruct&lt;sup id=&#34;fnref:18&#34;&gt;&lt;a href=&#34;#fn:18&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;18&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Moonshot AI&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;60%&lt;/td&gt;
          &lt;td&gt;65.8%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Jul-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;GLM-4.5&lt;sup id=&#34;fnref:19&#34;&gt;&lt;a href=&#34;#fn:19&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;19&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Z AI&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;64.2%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Jul-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;gpt-oss-120B&lt;sup id=&#34;fnref:20&#34;&gt;&lt;a href=&#34;#fn:20&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;20&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;OII&lt;/td&gt;
          &lt;td&gt;44.4%&lt;/td&gt;
          &lt;td&gt;62.4%&lt;/td&gt;
          &lt;td&gt;2622&lt;/td&gt;
          &lt;td&gt;Aug-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemini 2.5 Flash Thinking&lt;sup id=&#34;fnref:21&#34;&gt;&lt;a href=&#34;#fn:21&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;21&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;61.9%&lt;/td&gt;
          &lt;td&gt;60.4%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Aug-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemini 2.5 Pro&lt;sup id=&#34;fnref:22&#34;&gt;&lt;a href=&#34;#fn:22&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;22&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;82.2%&lt;/td&gt;
          &lt;td&gt;59.6%&lt;/td&gt;
          &lt;td&gt;2001&lt;/td&gt;
          &lt;td&gt;May-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;GLM-4.5-Air &lt;sup id=&#34;fnref1:19&#34;&gt;&lt;a href=&#34;#fn:19&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;19&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Z AI&lt;/td&gt;
          &lt;td&gt;OII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;57.6%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Jul-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude 3.7 Sonnet&lt;sup id=&#34;fnref1:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;64.9%&lt;/td&gt;
          &lt;td&gt;62.3%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Feb-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;o3-mini&lt;sup id=&#34;fnref3:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;61.0%&lt;/td&gt;
          &lt;td&gt;2036&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;gpt-oss-20B&lt;sup id=&#34;fnref1:20&#34;&gt;&lt;a href=&#34;#fn:20&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;20&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;OII&lt;/td&gt;
          &lt;td&gt;34.2%&lt;/td&gt;
          &lt;td&gt;60.7%&lt;/td&gt;
          &lt;td&gt;2516&lt;/td&gt;
          &lt;td&gt;Aug-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek-R1-0528 (2025)&lt;sup id=&#34;fnref:23&#34;&gt;&lt;a href=&#34;#fn:23&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;23&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;57.60% (Multiple Attempts)&lt;/td&gt;
          &lt;td&gt;1930&lt;/td&gt;
          &lt;td&gt;May-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-235B-A22B&lt;sup id=&#34;fnref:24&#34;&gt;&lt;a href=&#34;#fn:24&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;24&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;52.2&lt;sup id=&#34;fnref1:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;2056&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Grok 3&lt;sup id=&#34;fnref:25&#34;&gt;&lt;a href=&#34;#fn:25&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;25&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;xAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;53.3%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Feb-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek R1 (01/20)&lt;sup id=&#34;fnref:26&#34;&gt;&lt;a href=&#34;#fn:26&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;26&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;56.9%&lt;/td&gt;
          &lt;td&gt;49.2%&lt;/td&gt;
          &lt;td&gt;1530&lt;/td&gt;
          &lt;td&gt;Jan-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek V3 (03/24)&lt;sup id=&#34;fnref1:16&#34;&gt;&lt;a href=&#34;#fn:16&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;16&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;45.4%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Mar-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Mistral Medium 3&lt;sup id=&#34;fnref:27&#34;&gt;&lt;a href=&#34;#fn:27&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;27&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Mistarl&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;May-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ChatGPT 4.1&lt;sup id=&#34;fnref:28&#34;&gt;&lt;a href=&#34;#fn:28&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;28&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;55%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude 3.5 Sonnet&lt;sup id=&#34;fnref:29&#34;&gt;&lt;a href=&#34;#fn:29&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;29&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;49%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Oct-2024&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;o1&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;48.9%&lt;/td&gt;
          &lt;td&gt;1891&lt;/td&gt;
          &lt;td&gt;Dec-2024&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-32B&lt;sup id=&#34;fnref1:24&#34;&gt;&lt;a href=&#34;#fn:24&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;24&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;OII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;1977&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-30B-A3B&lt;sup id=&#34;fnref2:24&#34;&gt;&lt;a href=&#34;#fn:24&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;24&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;OII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;1974&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-14B&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;OIII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-8B&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;OIII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;del&gt;DeepSeek-R1-Distill-70B&lt;/del&gt;&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;OII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;1633&lt;/td&gt;
          &lt;td&gt;Jan-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Phi 4 reasoning (14B)&lt;/td&gt;
          &lt;td&gt;Microsoft&lt;/td&gt;
          &lt;td&gt;OIII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;1736&lt;/td&gt;
          &lt;td&gt;Dec-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Phi 4 reasoning plus&lt;/td&gt;
          &lt;td&gt;Microsoft&lt;/td&gt;
          &lt;td&gt;OIII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;1723&lt;/td&gt;
          &lt;td&gt;Dec-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-4B&lt;sup id=&#34;fnref3:24&#34;&gt;&lt;a href=&#34;#fn:24&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;24&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;OIII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;1671&lt;/td&gt;
          &lt;td&gt;Apr-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemma3-27B-IT&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;OII&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;1063&lt;/td&gt;
          &lt;td&gt;Mar-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek V3 (12/24)&lt;sup id=&#34;fnref:30&#34;&gt;&lt;a href=&#34;#fn:30&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;30&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;42%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Dec-2024&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude 3.5 Haiku&lt;sup id=&#34;fnref:31&#34;&gt;&lt;a href=&#34;#fn:31&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;31&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;40.6%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Oct-2024&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;del&gt;o1-preview&lt;/del&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;40%&lt;/td&gt;
          &lt;td&gt;1258&lt;/td&gt;
          &lt;td&gt;Sep-2024&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ChatGPT 4.5&lt;sup id=&#34;fnref:32&#34;&gt;&lt;a href=&#34;#fn:32&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;32&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;38.0%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Feb-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude 3.5 Sonnet (old)&lt;sup id=&#34;fnref1:29&#34;&gt;&lt;a href=&#34;#fn:29&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;29&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;33.4%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Jun-2024&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ChatGPT 4o&lt;sup id=&#34;fnref1:32&#34;&gt;&lt;a href=&#34;#fn:32&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;32&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;33.2%&lt;/td&gt;
          &lt;td&gt;900&lt;/td&gt;
          &lt;td&gt;May-2024&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;o1-mini&lt;sup id=&#34;fnref:33&#34;&gt;&lt;a href=&#34;#fn:33&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;33&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;30%&lt;/td&gt;
          &lt;td&gt;1650&lt;/td&gt;
          &lt;td&gt;Sep-2024&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude 3 Opus&lt;sup id=&#34;fnref2:29&#34;&gt;&lt;a href=&#34;#fn:29&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;29&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;22%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Mar-2024&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;definition-of-tier&#34; &gt;Definition of Tier
&lt;span&gt;
    &lt;a href=&#34;#definition-of-tier&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Tier&lt;/th&gt;
          &lt;th&gt;Name&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;P&lt;/td&gt;
          &lt;td&gt;Proprietary&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;O&lt;/td&gt;
          &lt;td&gt;Open Weights&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;I&lt;/td&gt;
          &lt;td&gt;Flagship&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;Dedicated Hardware (32GB &amp;lt; VRAM &amp;lt;= 144 GB)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;III&lt;/td&gt;
          &lt;td&gt;&amp;lt;= 32GB VRAM&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;IV&lt;/td&gt;
          &lt;td&gt;Speed&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When I say dedicated hardware, I&amp;rsquo;m talking about having to buy hardware dedicated for running AI models locally. The best bang for you buck available as far as I know is &lt;a href=&#34;https://tinygrad.org/#tinybox&#34;&gt;tiny box&lt;/a&gt; or &lt;a href=&#34;https://itsalltruffles.com/&#34;&gt;Truffle&lt;/a&gt; with the former costing over 10k and the latter costing under 20k. I mean at that price point, unless you&amp;rsquo;re doing something sensitive, it&amp;rsquo;s better to use API endpoints via openrouter.&lt;/p&gt;
&lt;h3 id=&#34;notes&#34; &gt;Notes
&lt;span&gt;
    &lt;a href=&#34;#notes&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Google Gemini 2.5 Pro May update is missing from the leaderboard&lt;/li&gt;
&lt;li&gt;I&amp;rsquo;m disappointed in the Grok team at xAI for failing to release benchmarks that can be compared against future frontier models (Gemini 2.5 Pro was released in March 2025, o4-mini was released in April 2025, and Qwen3 in April 2025). Their benchmark only proves that Grok 3 Beta and Grok 3 mini Beta (THINK) outperform o3-mini. They only really used LiveCodeBench which like I said before, is not a good way to do comparison across time. On LiveCodeBench, Grok 3 Beta scored higher than o3-mini and Deepseek-R1, but nothing really to compare against Gemini 2.5 Pro, which is the frontier model that got released after Grok 3. Even when Gemini 2.5 Pro was released, Grok 3 Beta&amp;rsquo;s SWE-bench verified score was and is still &lt;code&gt;-&lt;/code&gt;. Amongst all the models Gemini 2.5 Pro compared against, Grok 3 Beta was the one with the most missing benchmarks (6). And that&amp;rsquo;s with the Gemini team excluding Claude 3.7&amp;rsquo;s &lt;a href=&#34;https://gr.inc/OpenAI/SimpleQA/&#34;&gt;estimated SimpleQA score&lt;/a&gt; of ~50.&lt;/li&gt;
&lt;li&gt;I put R1 above o1 because R1 was better at software &lt;em&gt;engineering&lt;/em&gt; not just programming. The example I can give is asking about fixing a race condition regarding writing to a file that needs to be read. R1 properly told me to use &lt;code&gt;fsync&lt;/code&gt; (note: call &lt;code&gt;F_FULLFSYNC&lt;/code&gt; for Darwin platforms)&lt;/li&gt;
&lt;li&gt;The codeforces scores change depending on when they are recorded. This is the case for DeepSeek R1, which got a bump of ~150. I did this to ensure that Qwen3 models that don&amp;rsquo;t contain a SWE-bench verified score are not ranked above DeepSeek R1. I also removed Claude 3.5 Sonnet&amp;rsquo;s Codeforces score because there was apparently a (new) model released for it which has clearly not been benchmarked by the new models. It&amp;rsquo;s a bit weird that the new Qwen release does not benchmark claude 3.7.&lt;/li&gt;
&lt;li&gt;Explaining Synthetic Rankings of models with missing scores.
&lt;ul&gt;
&lt;li&gt;According to Mistral, Mistral Medium 3 performs just below Claude 3.7 and ranks DeepSeek V3 (03/24) above Claude 3.7 according to their LiveCodeBench benchmarking. However, until I see an updated SWE-bench verified on Mistral Medium 3, it will be placed below DeepSeek V3&lt;/li&gt;
&lt;li&gt;Qwen3-235B-A22B and Grok 3 are only placed so high due to outperforming o3-mini and DeepSeek R1 at the LiveCodeBench. Surprisingly, Gemini 2.5 Pro has the highest LiveCodeBench score according to Qwen&amp;rsquo;s blog. Therefore, it makes sense to ignore the CodeForces when computing the synthetic ranking for Qwen3-235B-A22B and Grok 3. Reasoning models are also worse for productivity because they take longer to respond.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;interpreting-the-leaderboard&#34; &gt;Interpreting the Leaderboard
&lt;span&gt;
    &lt;a href=&#34;#interpreting-the-leaderboard&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;2025-05-05&lt;/p&gt;
&lt;p&gt;Models that are prohibitively expensive: o3 (high), claude 3.7 + thinking.&lt;/p&gt;
&lt;p&gt;In my opinion, given that Claude 3.7 sucks at following simple instructions and behaves like an intern when it modifies code it was told not to edit, the models I recommend as of comes down to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;o3 (too expensive?)&lt;/li&gt;
&lt;li&gt;o4-mini&lt;/li&gt;
&lt;li&gt;gemini-2.5-pro-preview&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusions&#34; &gt;Conclusions
&lt;span&gt;
    &lt;a href=&#34;#conclusions&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Why can&amp;rsquo;t I get paid to do this? If I was paid money, I would HAPPILY run benchmarks on all frontier models and maintain the leaderboards for all the necessary models. Hell I would even make a fancy UI and everything instead of just a static markdown table that can&amp;rsquo;t be sorted.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;EvalPlus is deprecated; read more in the coding leaderboard&lt;/li&gt;
&lt;li&gt;LCB scores are static and the depreciation mechanism makes it very difficult to compare a model that was just released to a model realeased a few months ago. For example, look at Grok 3. They exclusively use this benchmark, even though there&amp;rsquo;s a 99.99% chance that Grok 3&amp;rsquo;s future LCB score would be lower. This is exhibited well in Qwen&amp;rsquo;s blog which showed Gemini 2.5 Pro absolutely crushing LCB. The biggest issues for LCB is that if you have a restraint like &amp;ldquo;I only want to run open-source models less than 20B in size&amp;rdquo;, you will definitely not be able to benefit from LCB&amp;rsquo;s own published leaderboards.&lt;/li&gt;
&lt;li&gt;xAI is releasing a suspicuiously low amount of benchmark scores. Not only that, but the xAI team has taken the approach that we all have patience. Their LCB score is useless to real world scenarios once you realize not only did it have to think to achieve them, gemini 2.5 pro beat it anyways. Not to mention that o4-mini and Gemini 2.5 Pro Preview were released on openrouter 7-8 days after grok 3 BETA was released on openrouter.&lt;/li&gt;
&lt;li&gt;Qwen3 30B is a great model and has &amp;ldquo;deprecated&amp;rdquo; DeepSeek R1 Distill 70B&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;history-of-releases&#34; &gt;History of Releases
&lt;span&gt;
    &lt;a href=&#34;#history-of-releases&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Anthropic: Claude 3 Opus scored scored 22% on SWE-bench verified, the paper was released later in August&lt;/li&gt;
&lt;li&gt;OpenAI: ChatGPT 4o May 2025 scored 33.2% on SWE-bench verified
They started off very strong in June 2024 with 3.5 Sonnet, but are slowly plateauing in performance&lt;/li&gt;
&lt;li&gt;Anthropic: Claude 3.5 released in June, revolutionary even though on paper it was only 33.4%&lt;/li&gt;
&lt;li&gt;Anthropic: Claude 3.5 released in June, revolutionary even though on paper it was only 33.4%&lt;/li&gt;
&lt;li&gt;OpenAI: o1 preview and mini, the latter of which scores 30%, the former was scoring 40%.&lt;/li&gt;
&lt;li&gt;Anthropic: October update Claude 3.5 Haiku scores 40.6% and the new Claude 3.5 Sonnet scores 49%, crowing it 2024&amp;rsquo;s best model&lt;/li&gt;
&lt;li&gt;OpenAI: o1 released in Dec-2024 with a score of 48.9%&lt;/li&gt;
&lt;li&gt;DeepSeek: V3 (open-weight) released in Dec-2024 with a score of 42%!
2025&lt;/li&gt;
&lt;li&gt;DeepSeek: R1 (open) release in Jan-2025 with a score of 49.2%! Everyone started going crazy&lt;/li&gt;
&lt;li&gt;Grok: Announces 3 Beta on 19th (still can&amp;rsquo;t find official 3 non-beta release blog post LOL) with some LCB scores&lt;/li&gt;
&lt;li&gt;Anthropic: Sonnet 3.7 released on 24th; Raised the bar to the next level at 62.3%&lt;/li&gt;
&lt;li&gt;OpenAI: disappointing chat gpt 4.5 release (Feb 27th)&lt;/li&gt;
&lt;li&gt;Google: Fully releases Gemini 2.5 Pro in Mar-2025 with a score of 67.2%, also release Gemma3, but not as relevant&lt;/li&gt;
&lt;li&gt;DeepSeek: V3 refresher&lt;/li&gt;
&lt;li&gt;OpenAI: Strikes back with o3 in Apr-2025 with a score of 69.1%&lt;/li&gt;
&lt;li&gt;Qwen: Qwen3 (open) released in Apr-2025, offers better performance for less size than DeepSeek R1 distills (made me very optimistic about open-weight models)&lt;/li&gt;
&lt;li&gt;Anthropic: Claude 4 Sonnet comes in at 72.7% in may&lt;/li&gt;
&lt;li&gt;DeepSeek: R1 refresh improves score to 57.6%&lt;/li&gt;
&lt;li&gt;Grok: 4 release, leaked scores showing a &amp;ldquo;code&amp;rdquo; model scoring 75% on swe-bench verified. Removed from my leaderboard. They only compared to Gemini 2.5 Pro which was at that point &amp;ldquo;inferior&amp;rdquo; to both o3, and 4&lt;/li&gt;
&lt;li&gt;Z, Kimi, Qwen: July was a win for open source with all three companies releasing models. Qwen 3 Coder 480B replaced R1 as the open SOTA score at 69.6%. Z&amp;rsquo;s GLM 4.5 Air showed that performance does not need to come with unattainable hardware.&lt;/li&gt;
&lt;li&gt;August: OpenAI (open-source models, best performance at 20B - consumer level), 120B released redundant due to GLM 4.5 Air, Deepseek V3.1, Anthropic 4.1 opus SOTA 74.5%, Grok code-fast (very good performance for quick response time)&lt;/li&gt;
&lt;li&gt;Septemeber: OpenAI codex + gpt5, Grok 4 Fast, V3.1 refresh&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Anthropic started 2024 behind OpenAI but aggressively leapfrogged the competition multiple times to stay near the top&lt;/p&gt;
&lt;p&gt;Qwen and DeepSeek reduced the performance gap. They are at the heels of proprietary companies. Open SOTA is 69.6% for swe-bench verified in July 2025 vs. 74%+ scores which came out in August and September 2025. If we go back to July 2025, only Anthropic was ahead at 72.5%.&lt;/p&gt;
&lt;p&gt;OpenAI: Codex and gpt 5 is significant, but..&lt;/p&gt;
&lt;p&gt;Grok: Grok Code Fast and Grok 4 shows that Grok team is changing direction and focusing on results and specialization rather than generalization. Their Code Fast models make them a company to take more seriously.&lt;/p&gt;
&lt;p&gt;Google: Google seems to take it laid back (deserving so). The 2.5 Pro May update is not benchmarked as much but it keeps their model relevant. Google seems to focus on releasing models to maintain relevancy rather than cater to benchmark scores.&lt;/p&gt;
&lt;h2 id=&#34;references&#34; &gt;References
&lt;span&gt;
    &lt;a href=&#34;#references&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;DeepSeek R1 claims 96.3th percentile which is [1989, 2095]&lt;sup id=&#34;fnref:34&#34;&gt;&lt;a href=&#34;#fn:34&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;34&lt;/a&gt;&lt;/sup&gt; However OpenAI claims a score of 1891. Since DeepSeek reported that o1 has a higher codeforces percentile, we can assume that DeepSeek R1&amp;rsquo;s score should be strictly less than o1&amp;rsquo;s codeforces score, which is 1890 at best.&lt;/p&gt;
&lt;p&gt;DeepSeek V3 claims 51.6th percentile and most recently 58.7th percentile. Given that R1 is below that percentile, I&amp;rsquo;ve used the lowest 51th percentile (assuming that the median barely moved up).&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://x.ai/news/grok-4-fast&#34;&gt;Grok 4 Fast&lt;/a&gt; scores higher than Grok 4 on the same LiveCodeBench (Jan-May 2025)&lt;sup id=&#34;fnref:35&#34;&gt;&lt;a href=&#34;#fn:35&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;35&lt;/a&gt;&lt;/sup&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.anthropic.com/news/claude-sonnet-4-5&#34;&gt;Introducing Claude Sonnet 4.5&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/introducing-upgrades-to-codex&#34;&gt;Introducing Upgrades to Codex - OpenAI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/introducing-codex/&#34;&gt;Introducing Codex&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.anthropic.com/news/claude-opus-4-1&#34;&gt;Claude Opus 4.1 - Anthropic&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.anthropic.com/news/claude-4&#34;&gt;Introducing Claude 4&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://x.ai/news/grok-code-fast-1&#34;&gt;Grok Code Fast 1 News - xAI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.anthropic.com/news/claude-3-7-sonnet&#34;&gt;Claude 3.7 Sonnet - Anthropic&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.google/products/gemini/gemini-2-5-pro-updates/&#34;&gt;Build rich, interactive web apps with an updated Gemini 2.5 Pro&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://qwen3lm.com/&#34;&gt;Qwen3 Coder - Agentic Coding Adventure&lt;/a&gt; (see picture beside &amp;ldquo;What Is Qwen3 Coder?&amp;rdquo;)&amp;#160;&lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:11&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/introducing-o3-and-o4-mini&#34;&gt;Introducing O3 and O4 Mini - OpenAI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref2:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref3:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:12&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://qwen.ai/blog?id=241398b9cd6353de490b0f82806c7848c5d2777d&amp;amp;from=research.latest-advancements-list&#34;&gt;Qwen3-Max: Just Scale it&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:13&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://api-docs.deepseek.com/news/news250922&#34;&gt;DeepSeek-V3.1-Terminus&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:13&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:14&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://api-docs.deepseek.com/news/news250929&#34;&gt;Introducing DeepSeek-V3.2-Exp&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:14&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:15&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://z.ai/blog/glm-4.6&#34;&gt;GLM-4.6: Advanced Agentic, Reasoning and Coding Capabilities&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:15&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:16&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://api-docs.deepseek.com/news/news250821&#34;&gt;DeepSeek-V3.1&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:16&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:16&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:17&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://ai.meta.com/research/publications/cwm-an-open-weights-llm-for-research-on-code-generation-with-world-models/&#34;&gt;CWM: An Open-Weights LLM for Research on Code Generation with World Models&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:17&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:18&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/MoonshotAI/Kimi-K2&#34;&gt;Kimi-K2 - Moonshot AI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:18&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:19&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://z.ai/blog/glm-4.5&#34;&gt;GLM-4.5: Reasoning, Coding, and Agentic Abililties&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:19&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:19&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:20&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf&#34;&gt;OpenAI GPT-OSS Model Card - OpenAI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:20&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:20&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:21&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://deepmind.google/models/gemini/flash/&#34;&gt;Gemini Flash (2025-09-27)&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:21&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:22&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#gemini-2-5-pro&#34;&gt;Gemini Model Thinking Updates March 2025 - Google DeepMind&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:22&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:23&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://api-docs.deepseek.com/news/news250528&#34;&gt;DeepSeek-R1-0528 Release&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:23&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:24&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://qwen.ai/blog?id=1e3fa5c2d4662af2855586055ad037ed9e555125&amp;amp;from=research.research-list&#34;&gt;Qwen3: Think Deeper, Act Faster&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:24&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:24&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref2:24&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref3:24&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:25&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://x.ai/news/grok-3&#34;&gt;Grok 3 Beta  The Age of Reasoning Agents&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:25&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:26&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://api-docs.deepseek.com/news/news250120&#34;&gt;DeepSeek API News 2025-01-20 - DeepSeek&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:26&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:27&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://mistral.ai/news/mistral-medium-3&#34;&gt;Mistral Medium 3 News - Mistral AI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:27&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:28&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/gpt-4-1&#34;&gt;GPT-4.1 - OpenAI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:28&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:29&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.anthropic.com/engineering/swe-bench-sonnet&#34;&gt;Raising the bar on SWE-bench Verified with Claude 3.5 Sonnet&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:29&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:29&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref2:29&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:30&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://api-docs.deepseek.com/news/news1226&#34;&gt;Introducing DeepSeek-V3&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:30&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:31&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.anthropic.com/news/3-5-models-and-computer-use&#34;&gt;Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:31&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:32&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/introducing-gpt-4-5&#34;&gt;Introducing GPT-4.5 - OpenAI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:32&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:32&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:33&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning&#34;&gt;O1 Mini: Advancing Cost-Efficient Reasoning - OpenAI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:33&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:34&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://codeforces.com/blog/entry/126802&#34;&gt;2024 Codeforces Rating Distribution + rating percentiles&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:34&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:35&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://x.com/legit_api/status/1941165728708874514&#34;&gt;Grok-4 and Grok-4 Code on benchmarks - x/@legit_api leak&lt;/a&gt;; Grok 4 has a higher LiveCodeBench score than all the other models for &lt;a href=&#34;https://1drv.ms/b/c/7FD1036D7D077AF4/EXmAOOAkOFJPkoIE-4h9N1EBz4MJk1LCfI_SPejC7gfeGg?e=SYSsJB&#34;&gt;Jan 2025 to May 2025&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:35&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>AI Awesome List</title>
      <link>https://blog.elijahlopez.ca/posts/ai/</link>
      <pubDate>Fri, 02 May 2025 22:55:04 -0400</pubDate>
      
      <guid>https://blog.elijahlopez.ca/posts/ai/</guid>
      <description>&lt;p&gt;Please drop a comment if you think something is missing or want something added.&lt;/p&gt;
&lt;p&gt;Ever since the launch of ChatGPT, AI powered apps have been blowing up. Every single day there&amp;rsquo;s a new AI powered app that solves a specific use case. Some of which I have no need for, but are good to know.
There&amp;rsquo;s two ways to keep up to date with AI, one is to subscribe to a newsletter, and the other is to bookmark a list, so that&amp;rsquo;s what this is going to be. The problem with existing lists are their scope or vision sucks or they are not bleeding edge.
This list aims to be bleeding edge and will remove unmaintained / crap projects. It also aims to categorize AI so that everybody from hacker enthusiasts to corporate overlords will benefit. I&amp;rsquo;ve looked at other lists and they do a piss poor job of moderation. An awesome list shouldn&amp;rsquo;t be recommending crap TTS products to the user.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s two parts to this article. One focuses on the models and how to select them, whereas&lt;/p&gt;
&lt;div&gt;
    &lt;h2&gt;Table of Contents&lt;/h2&gt;
    &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#ai-models&#34;&gt;AI Models&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#benchmarks&#34;&gt;Benchmarks&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#evaluation-platform&#34;&gt;Evaluation Platform&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#proprietary-models&#34;&gt;Proprietary Models&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#text-to-image&#34;&gt;Text to Image&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#open-source-models&#34;&gt;Open-Source Models&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#ai-api-providers&#34;&gt;AI API Providers&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#running-in-the-cloud&#34;&gt;Running in the Cloud&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#ai-applications&#34;&gt;AI Applications&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#chat&#34;&gt;Chat&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#recall-rag&#34;&gt;Recall (RAG)&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#ai-search&#34;&gt;AI Search&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#interesting-media-research&#34;&gt;Interesting Media Research&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#image&#34;&gt;Image&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#video&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#audio&#34;&gt;Audio&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#3d&#34;&gt;3D&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#websites&#34;&gt;Websites&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#creating-mobile-apps-with-ai&#34;&gt;Creating Mobile Apps with AI&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#marketing&#34;&gt;Marketing&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#software-development&#34;&gt;Software Development&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#cybersecurity&#34;&gt;CyberSecurity&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#using-ai-in-applications&#34;&gt;Using AI in Applications&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#writing&#34;&gt;Writing&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#white-collar-workers&#34;&gt;White Collar Workers&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#other-ai-apps&#34;&gt;Other AI Apps&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#what-else-can-you-accomplish-with-ai&#34;&gt;What else can you accomplish with AI?&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#ai-research&#34;&gt;AI Research&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#local-ai-models&#34;&gt;Local AI Models&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#how-to-run-open-source-models&#34;&gt;How to Run Open-Source Models&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#open-source-interfaces&#34;&gt;Open-Source Interfaces&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#interfaces&#34;&gt;Interfaces&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#learning&#34;&gt;Learning&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#read-frontier-papers&#34;&gt;Read Frontier Papers&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#follow-ai-researchers&#34;&gt;Follow AI Researchers&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#get-resources&#34;&gt;Get Resources&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#ai-research-companies&#34;&gt;AI Research Companies&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#ai-product-companies&#34;&gt;AI Product Companies&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#ai-hardware&#34;&gt;AI Hardware&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#jargon&#34;&gt;Jargon&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#final-words&#34;&gt;Final Words&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;h2 id=&#34;ai-models&#34; &gt;AI Models
&lt;span&gt;
    &lt;a href=&#34;#ai-models&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;I&amp;rsquo;m starting with the topic of benchmarks because the best way to be ahead is by using the forefront leader in AI which is only possible by reading benchmark scores. One day it could be OpenAI, the next Google, the next some whale named DeepSeek, and then something called Qwen. Truly, it&amp;rsquo;s better to make informed decisions based on a heuristic than it is to blindly follow the sheep and limit yourself a single platform.&lt;/p&gt;
&lt;h3 id=&#34;benchmarks&#34; &gt;Benchmarks
&lt;span&gt;
    &lt;a href=&#34;#benchmarks&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;In my opinion, the current state of benchmarks is very messy. I&amp;rsquo;m making progress on fixing it myself with blog posts such as &lt;a href=&#34;https://blog.elijahlopez.ca/posts/ai-simpleqa-leaderboard/&#34;&gt;SimpleQA Leaderboard&lt;/a&gt; however, there are a few more I would like to maintain. I suggest using these benchmarks as a heuristic in finding a handful of models to test yourself before going with one of them.&lt;/p&gt;
&lt;h4 id=&#34;populist-benchmarks&#34; &gt;Populist Benchmarks
&lt;span&gt;
    &lt;a href=&#34;#populist-benchmarks&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h4&gt;&lt;p&gt;I&amp;rsquo;m naming these populist benchmarks because it&amp;rsquo;s basically a popularity contest (real and synthetic) rather than a merit-based benchmark.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://lmarena.ai/?leaderboard&#34;&gt;Chatbot Arena LLM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/lmarena/arena-hard-auto?tab=readme-ov-file#leaderboard&#34;&gt;ArenaHard&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;intelligence&#34; &gt;Intelligence
&lt;span&gt;
    &lt;a href=&#34;#intelligence&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arcprize.org/leaderboard&#34;&gt;ARC-AGI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://app.promptjudy.com/public-runs&#34;&gt;Prompt Judy&lt;/a&gt; - Named Entity Recognition Dataset 2, Complex OCR&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Intelligence benchmarks are good because you can also figure out which models are good at I/O tasks. Meaning you can give instructions to the model on what to do for each input, and the model returns output based on the input. This is applied intelligence which is a good thing to measure.&lt;/p&gt;
&lt;h4 id=&#34;knowledge-benchmarks&#34; &gt;Knowledge Benchmarks
&lt;span&gt;
    &lt;a href=&#34;#knowledge-benchmarks&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://artificialanalysis.ai/evaluations/gpqa-diamond&#34;&gt;GPQA : Graduate-Level Google-Proof Q&amp;amp;A Benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.elijahlopez.ca/posts/ai-simpleqa-leaderboard/&#34;&gt;SimpleQA (Factuality)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://matharena.ai/&#34;&gt;AIME (Math)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lastexam.ai/&#34;&gt;Humanity&amp;rsquo;s Last Exam&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;coding-benchmarks&#34; &gt;Coding Benchmarks
&lt;span&gt;
    &lt;a href=&#34;#coding-benchmarks&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://web.lmarena.ai/leaderboard&#34;&gt;WebDev Arena Leaderboard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.designarena.ai/&#34;&gt;Design arena&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.elijahlopez.ca/posts/ai-coding-leaderboard/&#34;&gt;SWE-Bench verified&lt;/a&gt;: Software Engineering. (&lt;a href=&#34;https://www.swebench.com/#test&#34;&gt;leaderboard with all tools&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.elijahlopez.ca/posts/ai-coding-leaderboard/&#34;&gt;CodeForces&lt;/a&gt;: Competitive programming (note that there is no time penalty for the models)&lt;/li&gt;
&lt;li&gt;&lt;del&gt;&lt;a href=&#34;https://livecodebench.github.io/leaderboard.html&#34;&gt;LiveCodeBench&lt;/a&gt;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;&lt;a href=&#34;https://evalplus.github.io/leaderboard.html&#34;&gt;EvalPlus&lt;/a&gt;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;Aider Polyglot (Code Editing)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The problem with LiveCodeBench is that there are different cut off dates depending on when a model is graded plus the benchmark is continuously updated. When using the earliest cut off date, some models might&amp;rsquo;ve been &amp;ldquo;contaminated&amp;rdquo; and when using later cut off dates, some models do not show up at all! If we use the scores self-reported by the company, we still run the risk of reporting non-comparable numbers. Based on how LCB works, model scores are expected to depreciate over the long run; If Grok 3 scored 100 on LCB today, it is almost certain to score less than 100 in a year.&lt;/p&gt;
&lt;p&gt;The problem with EvalPlus is that it doesn&amp;rsquo;t include bleeding edge models, it&amp;rsquo;s basically almost solved, and not many new models even report their scores anymore.&lt;/p&gt;
&lt;h4 id=&#34;multimodal-benchmarks&#34; &gt;Multimodal Benchmarks
&lt;span&gt;
    &lt;a href=&#34;#multimodal-benchmarks&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h4&gt;&lt;p&gt;This tests visual capabilities.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MMMU (College-level visual problem-solving)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lastexam.ai/&#34;&gt;Humanity&amp;rsquo;s Last Exam&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;writing-benchmarks&#34; &gt;Writing Benchmarks
&lt;span&gt;
    &lt;a href=&#34;#writing-benchmarks&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://eqbench.com/&#34;&gt;eqbench&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;agentic-benchmarks&#34; &gt;Agentic Benchmarks
&lt;span&gt;
    &lt;a href=&#34;#agentic-benchmarks&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h4&gt;&lt;p&gt;Agentic benchmarks are very new and personally I&amp;rsquo;m not too sure what these benchmarks do or even what is considered good. Personally the only agent I would ever value is one that has the same worth ethic and intelligence as I am during when I&amp;rsquo;m at my peak productivity.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scale MultiChallenge&lt;/li&gt;
&lt;li&gt;BrowseComp&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation-platform&#34; &gt;Evaluation Platform
&lt;span&gt;
    &lt;a href=&#34;#evaluation-platform&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/open-compass/opencompass&#34;&gt;OpenCompass&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/MoonshotAI/K2-Vendor-Verfier&#34;&gt;K2 Vendor Verifier&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;proprietary-models&#34; &gt;Proprietary Models
&lt;span&gt;
    &lt;a href=&#34;#proprietary-models&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Model Name&lt;/th&gt;
          &lt;th&gt;Company&lt;/th&gt;
          &lt;th&gt;Blog&lt;/th&gt;
          &lt;th&gt;Chat App&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://deepmind.google/technologies/gemini/&#34;&gt;Gemini&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://deepmind.google/discover/blog/&#34;&gt;Google DeepMind Blog&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://aistudio.google.com/prompts/new_chat&#34;&gt;Google AI Studio&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://platform.openai.com/docs/models&#34;&gt;OpenAI Platform&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://openai.com/news/&#34;&gt;news&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://chatgpt.com/&#34;&gt;ChatGPT&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://docs.x.ai/docs/models&#34;&gt;Grok&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;xAI&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://x.ai/news&#34;&gt;news&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://x.com/i/grok&#34;&gt;Grok&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.anthropic.com/claude&#34;&gt;Claude&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.anthropic.com/news&#34;&gt;news&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://claude.ai/&#34;&gt;Chat&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://cohere.com/command&#34;&gt;Cohere Platform&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Cohere&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://cohere.com/blog&#34;&gt;blog&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://dashboard.cohere.com/&#34;&gt;Dashboard&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Cohere is really slacking. I almost forgot about them.&lt;/p&gt;
&lt;h3 id=&#34;text-to-image&#34; &gt;Text to Image
&lt;span&gt;
    &lt;a href=&#34;#text-to-image&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/ArtificialAnalysis/Text-to-Image-Leaderboard&#34;&gt;ArtificialAnalysis/Text-to-Image-Leaderboard&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;open-source-models&#34; &gt;Open-Source Models
&lt;span&gt;
    &lt;a href=&#34;#open-source-models&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;A table of companies that release open-source LLMs. I suggest adding these to your RSS reader or signing up for email updates. In the future, hopefully RSSHub adds support for these.&lt;/p&gt;
&lt;p&gt;When it comes to downloading models, most vendors (that&amp;rsquo;s what I&amp;rsquo;m calling the companies) will link you to Hugging Face. My biggest gripe is how Hugging Face isn&amp;rsquo;t using P2P torrent technology to speed up downloads and reduce strain on their own servers! What a missed opportunity.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Model Family&lt;/th&gt;
          &lt;th&gt;Company&lt;/th&gt;
          &lt;th&gt;Blog&lt;/th&gt;
          &lt;th&gt;Chat App&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.DeepSeek.org/&#34;&gt;DeepSeek&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Chat Stream&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.DeepSeek.org/blog&#34;&gt;Chat Stream Blog&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.DeepSeek.org/en/chat&#34;&gt;DeepSeek Chat&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://qwenlm.github.io/&#34;&gt;Qwen&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;AliBaba&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://qwenlm.github.io/blog/&#34;&gt;Qwen Blog&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://chat.qwen.ai/&#34;&gt;Qwen Chat&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.llama.com/&#34;&gt;Llama&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Meta&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://ai.meta.com/blog/&#34;&gt;AI at Meta Blog&lt;/a&gt; and &lt;a href=&#34;https://ai.meta.com/research/&#34;&gt;Meta AI Research&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;OpenRouter&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://mistral.ai/products/la-plateforme#models&#34;&gt;Mistral&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Mistral&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://mistral.ai/news&#34;&gt;Mistral News&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://mistral.ai/products/le-chat&#34;&gt;Le Chat&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://ai.google.dev/gemma&#34;&gt;Gemma&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://deepmind.google/blog/&#34;&gt;DeepMind Blog&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://aistudio.google.com/prompts/new_chat&#34;&gt;Google AI Studio&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/phi/&#34;&gt;Phi&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Microsoft&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://techcommunity.microsoft.com/category/ai/blog/aiplatformblog&#34;&gt;Microsoft AI Platform Blog&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;OpenRouter or &lt;a href=&#34;https://ai.azure.com/explore/models?selectedCollection=phi&amp;amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47&#34;&gt;Azure AI Foundry&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://huggingface.co/THUDM&#34;&gt;ChatGLM&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;THUKEG &amp;amp; Z.ai&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://x.com/thukeg&#34;&gt;Twitter&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;OpenRouter&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note that sometimes proprietary models are open-sourced, but this usually happens long after a model from an open-source family has beaten the outdated proprietary model. Therefore, they are not included in this list for end-users.&lt;/p&gt;
&lt;p&gt;These are also the base models. If you go tho HuggingFace and LocalLLAMA, you can find many remixes (fine-tunes) of the base models to yield specific results. There are so many people doing this.&lt;/p&gt;
&lt;h3 id=&#34;ai-api-providers&#34; &gt;AI API Providers
&lt;span&gt;
    &lt;a href=&#34;#ai-api-providers&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;These companies don&amp;rsquo;t make the models, but offer inference, either by hosting models or via a gateway&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenRouter (one API provider to use many APIs)&lt;/li&gt;
&lt;li&gt;HuggingFace (which links to Amazon, Azure, and Google)&lt;/li&gt;
&lt;li&gt;Groq&lt;/li&gt;
&lt;li&gt;Together.ai&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://replicate.com/explore/&#34;&gt;Replicate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;running-in-the-cloud&#34; &gt;Running in the Cloud
&lt;span&gt;
    &lt;a href=&#34;#running-in-the-cloud&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://runpod.io/&#34;&gt;RunPod&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lium.io/register?ref=LIUM-0B3LXV4L&#34;&gt;lium&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ai-applications&#34; &gt;AI Applications
&lt;span&gt;
    &lt;a href=&#34;#ai-applications&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;AI but for specific tasks. A mix of apps and models (when applicable). Skip to &lt;a href=&#34;#local-ai-models&#34;&gt;Local AI Models&lt;/a&gt; to learn more about running open-source models using open-source apps&lt;/p&gt;
&lt;h3 id=&#34;chat&#34; &gt;Chat
&lt;span&gt;
    &lt;a href=&#34;#chat&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;The default type of application when people say LLMs.  and  for a list of models. Alternatively, if you don&amp;rsquo;t mind paying, an easy way to interact with all models is through &lt;a href=&#34;https://openrouter.ai/&#34;&gt;OpenRouter&lt;/a&gt;. Read &lt;a href=&#34;#how-to-run-open-source-models&#34;&gt;How to Run Open-Source Models&lt;/a&gt; if you want to run text generation models locally.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;#proprietary-models&#34;&gt;Proprietary Models&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;#open-source-models&#34;&gt;Open-Source Models&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Forefront AI&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bing Chat&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hugging Face&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Poe&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Merlin&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;WNR&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;recall-rag&#34; &gt;Recall (RAG)
&lt;span&gt;
    &lt;a href=&#34;#recall-rag&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;Using AI to boost productivity by letting AI do a domain search and recall on the content you provide. See section on &lt;a href=&#34;#jargon&#34;&gt;jargon&lt;/a&gt; to understand what RAG is.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://notebooklm.google/&#34;&gt;NotebookLM&lt;/a&gt;: a tool to understand information
&lt;ul&gt;
&lt;li&gt;TODO: somehow combine this with an RSS feed sync&lt;/li&gt;
&lt;li&gt;Can be used to combine a bunch of files together (pdfs, websites, youtube videos, audio, word files, etc)&lt;/li&gt;
&lt;li&gt;Can create a podcast out of it too&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.morphik.ai/&#34;&gt;Morphik AI&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;This is more for developers who want to build &lt;em&gt;enterprise applications&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ai-search&#34; &gt;AI Search
&lt;span&gt;
    &lt;a href=&#34;#ai-search&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;Some of these can also be considered a subset of &amp;ldquo;Chat&amp;rdquo;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://liner.com/&#34;&gt;Liner&lt;/a&gt; (specialized in getting answers with reliable sources which means helps to avoid plagiarism)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linkup.so/&#34;&gt;Linkup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://exa.ai/&#34;&gt;Exa&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.perplexity.ai/&#34;&gt;Perplexity&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;interesting-media-research&#34; &gt;Interesting Media Research
&lt;span&gt;
    &lt;a href=&#34;#interesting-media-research&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ai.meta.com/sam2/&#34;&gt;Segment Anything Model 2&lt;/a&gt; by Meta
&lt;ul&gt;
&lt;li&gt;example in &lt;a href=&#34;https://github.com/YavorGIvanov/sam.cpp&#34;&gt;sam.cpp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dinov2.metademolab.com/&#34;&gt;DINOv2&lt;/a&gt; by Meta&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aidemos.meta.com/videoseal&#34;&gt;Video Sea&lt;/a&gt; by Meta: add imperceptible,resilient, watermark to videos that can verify the video&amp;rsquo;s origin&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ai.meta.com/research/movie-gen/&#34;&gt;Meta Movie Gen&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://voicebox.metademolab.com/&#34;&gt;VoiceBox&lt;/a&gt; by Meta: generate speech, correct audio&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;image&#34; &gt;Image
&lt;span&gt;
    &lt;a href=&#34;#image&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Design &amp;amp; Editing
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://playground.com/&#34;&gt;Playground AI&lt;/a&gt;: Might not need to edit in Photoshop anymore (&lt;a href=&#34;https://x.com/Suhail/status/1674124521543192578&#34;&gt;demo&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;ChatGPT prompting&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://clipdrop.co/&#34;&gt;Clipdrop&lt;/a&gt; by Jasper (many tools like uncrop)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://uizard.io/autodesigner/&#34;&gt;Autodesigner 2.0&lt;/a&gt;: generate UI for apps/websites based on a prompt&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.usegalileo.ai/explore&#34;&gt;Galileo AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://x.com/umesh_ai/status/1901507907008782673&#34;&gt;Image editing via prompting in Gemini&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;AI can also be used to remove watermarks&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://x.com/madpencil_/status/1901584829038444707&#34;&gt;Gemini vs Photoshop example&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generative (Text-to-image or Image to Image)
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/ArtificialAnalysis/Text-to-Image-Leaderboard&#34;&gt;leaderboard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Open Source Models
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/stepfun-ai/Step1X-Edit&#34;&gt;Step1X-Edit&lt;/a&gt;: aims to open-source ChatGPT&amp;rsquo;s image capabilities&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://flux2.io/&#34;&gt;Flux.2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stability.ai/stable-image&#34;&gt;Stable Diffusion&lt;/a&gt; by StabilityAI (also see their Applications)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.midjourney.com/home&#34;&gt;Midjourney&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubadesign.lemonsqueezy.com/&#34;&gt;creating backgrounds with midjourney&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://x.com/adamlyttleapps/status/1671363003177123841&#34;&gt;Prompt to create app icons&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dream.ai/&#34;&gt;Dream&lt;/a&gt; by &lt;a href=&#34;https://dream.ai/blog&#34;&gt;WOMBO&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://comfyui-wiki.com/&#34;&gt;ComfyUI&lt;/a&gt;: GUI for diffusion modelsz&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://storybooklm.pro/&#34;&gt;Story Book LM Pro&lt;/a&gt;: Create illustration books for $8/mo&lt;/li&gt;
&lt;li&gt;Personal
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.headshotpro.com/&#34;&gt;Headshot Pro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://photoai.com/&#34;&gt;PhotoAI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;video&#34; &gt;Video
&lt;span&gt;
    &lt;a href=&#34;#video&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Generation
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://pika.art/&#34;&gt;Pika&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gemini.google/overview/video-generation/&#34;&gt;Veo&lt;/a&gt; by Google DeepMind&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lightricks.com/&#34;&gt;Lighttricks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;The largest model is 13B, so it can be run locally &lt;a href=&#34;https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master?tab=readme-ov-file#example-workflows&#34;&gt;using ComfyUI&lt;/a&gt;!&lt;/li&gt;
&lt;li&gt;9 seconds, 30 FPS, 720p&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stability.ai/stable-video&#34;&gt;Stable Diffusion Video&lt;/a&gt; by Stability AI&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sora.com&#34;&gt;Sora&lt;/a&gt; by OpenAI&lt;/li&gt;
&lt;li&gt;[Gen] by Runway (also includes research papers)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://x.com/rezkhere/status/1674412982716215296&#34;&gt;ChatGPT + Visla plugin&lt;/a&gt;: create a video commercial (voice over is trash though, use a TTS tool for that)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;audio&#34; &gt;Audio
&lt;span&gt;
    &lt;a href=&#34;#audio&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://deepmind.google/technologies/lyria/&#34;&gt;Lyria&lt;/a&gt; by Google DeepMind&lt;/li&gt;
&lt;li&gt;Music AI Sandbox is available through YouTube&amp;rsquo;s &lt;a href=&#34;https://blog.youtube/inside-youtube/partnering-with-the-music-industry-on-ai/&#34;&gt;Music AI Incubator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ai.meta.com/resources/models-and-libraries/audiocraft/&#34;&gt;AudioCraft&lt;/a&gt; by Meta&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/deezer/spleeter&#34;&gt;Spleeter&lt;/a&gt; by Deezer: source separation&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stability.ai/stable-audio&#34;&gt;Stable Audio&lt;/a&gt; by Stability AI&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://app.myshell.ai/robot-workshop&#34;&gt;Voice Cloning&lt;/a&gt; by MyShell
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/myshell-ai/OpenVoice&#34;&gt;OpenVoice&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/m-bain/whisperX&#34;&gt;WhisperX&lt;/a&gt; the best long-form transcription tool based on benchmarks done by &lt;a href=&#34;https://amgadhasan.substack.com/p/sota-asr-tooling-long-form-transcription&#34;&gt;Amgad Hasan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.vogent.ai/&#34;&gt;Vogent - Voice AI Agent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elevenlabs.io/&#34;&gt;ElevenLabs&lt;/a&gt;: (TTS, STT, Conversational, Dubbing, Voice cloning, reader)&lt;/li&gt;
&lt;li&gt;Text-to-Speech
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/nari-labs/Dia-1.6B&#34;&gt;Dia&lt;/a&gt; by Nari Labs (high quality for the patient)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/hexgrad/Kokoro-82M/&#34;&gt;kokoro-tts&lt;/a&gt; (fast and pretty good)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.myshell.ai/technology/melotts&#34;&gt;MeloTTS&lt;/a&gt; TTS by MeloTTS&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elevenlabs.io/&#34;&gt;ElevenLabs TTS&lt;/a&gt; (Jessica good)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3d&#34; &gt;3D
&lt;span&gt;
    &lt;a href=&#34;#3d&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://stability.ai/stable-3d&#34;&gt;Stable 3D&lt;/a&gt; by Stability AI&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Creating 3D wireframes with Gemini&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;This changes everything for 3D artists faster, easier, and endless possibilities. &lt;br&gt;&lt;br&gt;Google Gemini is awesome, try this prompt by bilawal: &lt;br&gt;edit this image to create a 3d wireframe representation of every unique object and subject in this scene. it should look like a blender 3d &lt;a href=&#34;https://t.co/MkJ57IMEvD&#34;&gt;https://t.co/MkJ57IMEvD&lt;/a&gt; &lt;a href=&#34;https://t.co/uTWWez2XHy&#34;&gt;pic.twitter.com/uTWWez2XHy&lt;/a&gt;&lt;/p&gt;&amp;mdash; Amira Zairi (@azed_ai) &lt;a href=&#34;https://twitter.com/azed_ai/status/1901418266746355999?ref_src=twsrc%5Etfw&#34;&gt;March 16, 2025&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;h3 id=&#34;websites&#34; &gt;Websites
&lt;span&gt;
    &lt;a href=&#34;#websites&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Creating one
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aurachat.io/&#34;&gt;Aura Chat&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aurachat.io/meng&#34;&gt;samples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;v0: for developers to speedrun website development&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.orchids.app/&#34;&gt;Orchids&lt;/a&gt;: &amp;ldquo;The AI Fullstack Engineer. Build prototypes, apps, and websites&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lovable.dev/&#34;&gt;Lovable&lt;/a&gt;: for developers to speedrun website development&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://uidesign.ai/&#34;&gt;UIDESIGN.AI&lt;/a&gt;: AI for Shopify Themes &amp;amp; Figma&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://combini.dev/r/redditvc&#34;&gt;combini&lt;/a&gt;: Full stack app builder&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bolt.new&#34;&gt;Bolt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://same.new&#34;&gt;Same&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://replit.com/&#34;&gt;Replit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.figma.com/sites/&#34;&gt;Figma Sites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gamma.app/&#34;&gt;Gamma&lt;/a&gt;: turn ideas into something real&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://postcheetah.com/&#34;&gt;Post Cheetah&lt;/a&gt;: Improve SEO with AI&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;creating-mobile-apps-with-ai&#34; &gt;Creating Mobile Apps with AI
&lt;span&gt;
    &lt;a href=&#34;#creating-mobile-apps-with-ai&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rork.app/&#34;&gt;Rork&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bolt.new&#34;&gt;Bolt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;marketing&#34; &gt;Marketing
&lt;span&gt;
    &lt;a href=&#34;#marketing&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://creatify.ai/&#34;&gt;Creatify&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://icon.com/&#34;&gt;Icon&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;software-development&#34; &gt;Software Development
&lt;span&gt;
    &lt;a href=&#34;#software-development&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;Aside from prompting the Chat apps, there are a variety of ways to use AI. I personally use Cline with an OpenRouter API key, however this is because I never got RooCode to work and so didn&amp;rsquo;t bother setting it up.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VSCode Integrations
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://roocode.com/&#34;&gt;Roo Code&lt;/a&gt; (Cline fork that is more community contribution friendly, previously Roo Cline)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cline.bot/&#34;&gt;Cline&lt;/a&gt; (as Debian is to Ubuntu, Cline is to RooCode)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/features/copilot&#34;&gt;GitHub Copilot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.continue.dev/&#34;&gt;Continue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twinny.dev/&#34;&gt;Twinny&lt;/a&gt; (not user-friendly at all and useful only for local models)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.qodo.ai/&#34;&gt;Qodo.ai&lt;/a&gt; (previously CodiumAI)
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Agentic AI for reviewing, testing , and generating code  continuous quality at every step&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other IDE Integrations
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aider.chat/&#34;&gt;Aider&lt;/a&gt;  (AI pair programming in your terminal)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.qodo.ai/products/qodo-gen/&#34;&gt;QoDo Gen&lt;/a&gt; (VsCode and JetBrains)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.continue.dev/&#34;&gt;Continue&lt;/a&gt; (VsCode and Jetbrains)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IDEs
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://windsurf.com/&#34;&gt;WindSurf&lt;/a&gt; (previously Codium, acquired by OpenAI in 2025)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cursor.com/&#34;&gt;Cursor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://trypear.ai/&#34;&gt;PearAI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.anthropic.com/en/docs/claude-code/overview&#34;&gt;Claude Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/AsyncFuncAI/deepwiki-open&#34;&gt;Open Source DeepWiki&lt;/a&gt;: Wiki Generator for GitHub/Gitlab Repositories&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://devin.ai/&#34;&gt;Devin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GitHub Integration
&lt;ul&gt;
&lt;li&gt;QoDo Merge&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;AI Coding Agents (via Terminal)
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aider.chat/&#34;&gt;aider&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/sst/opencode&#34;&gt;stt/opencode&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;more agentic&lt;/li&gt;
&lt;li&gt;connected to language server to course-correct&lt;/li&gt;
&lt;li&gt;always has context while in use&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/charmbracelet/crush&#34;&gt;charmbracelet/crush&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openai/codex&#34;&gt;openai/codex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/anthropics/claude-code&#34;&gt;anthropics/claude-code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/google-gemini/gemini-cli&#34;&gt;gemini-cli&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/QwenLM/qwen-code&#34;&gt;qwen-code&lt;/a&gt; (fork of gemini-cli)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CodebuffAI/codebuff&#34;&gt;codebuff&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.plandex.ai/hosting/self-hosting/local-mode-quickstart/&#34;&gt;plandex&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;no commits for 2+ months, lacks MCP and has some blockers for power users&lt;/li&gt;
&lt;li&gt;painful setup to use at cost&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/devflowinc/uzi&#34;&gt;uzi&lt;/a&gt; - haven&amp;rsquo;t really looked into it but it can run agents in parallel&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Figma to Code&lt;/p&gt;
&lt;p&gt;If you don&amp;rsquo;t mind TailwindCSS (I hate it), you may find these tools useful. Speaking from experience, you can just send Claude screenshots of the design and tell it to implement the design using a library like Mantine and it will implement it with 80% accuracy.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.veyrax.com/mcp&#34;&gt;VeyraX&lt;/a&gt; (&lt;a href=&#34;https://x.com/veyraxai/status/1900444154540236964&#34;&gt;Demo&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.superflex.ai/&#34;&gt;Superflex&lt;/a&gt; (demo on website)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cybersecurity&#34; &gt;CyberSecurity
&lt;span&gt;
    &lt;a href=&#34;#cybersecurity&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;-&lt;a href=&#34;https://peneterrer.com/&#34;&gt;peneterrer&lt;/a&gt;: AI Security Tester (pairs well with vibe coded websites)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We&amp;rsquo;re so confident in our security testing capabilities that if we don&amp;rsquo;t find any vulnerabilities, you get your money back. No questions asked.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;using-ai-in-applications&#34; &gt;Using AI in Applications
&lt;span&gt;
    &lt;a href=&#34;#using-ai-in-applications&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;openinterpreter.com/&#34;&gt;Open Interpreter&lt;/a&gt;: A natural language interface for computers&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://glama.ai/blog/2024-10-22-automate-computer-using-claude&#34;&gt;Computer Use by Anthropic guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dspy.ai/&#34;&gt;DSpy&lt;/a&gt; - modularizing AI by providing programmed functions that can be executed, thus lowering the risk of hallucinations for already solved problems
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://x.com/MaximeRivest/status/1929861781448536081?t=HmwYmLifYq1QJhSKavjL3g&#34;&gt;A simple introduction to DSPy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.cloudflare.com/connect-any-react-application-to-an-mcp-server-in-three-lines-of-code/&#34;&gt;React MCP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OpenRouter&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;writing&#34; &gt;Writing
&lt;span&gt;
    &lt;a href=&#34;#writing&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;I take great pride in stating that this blog post is ironically 100% free of AI generation. I&amp;rsquo;m not opposed to AI but knowing that AI is a FLUFF GENERATOR means that I can really only use AI to turn a bland writing post into a pleasant post (see &lt;a href=&#34;https://blog.elijahlopez.ca/posts/the-dog-food-eating-convention/&#34;&gt;That Time I Went to a Dog Food Eating Convention&lt;/a&gt;). If you rely on AI 100%, it can make your content over the top sweet, so I find the best way to use it on your own words is to incorporate some of its suggestions rather than all.&lt;/p&gt;
&lt;p&gt;I have two book ideas I want to pursue one day in the future. What I don&amp;rsquo;t approve of using AI for, is to generate redundant slop, which is basically plagiarism. &lt;a href=&#34;https://jetpack.com/ai/&#34;&gt;Jetpack AI&amp;rsquo;s&lt;/a&gt; own demo shows itself generating slop. Using AI to write a blog post about being a better blogger? What? I think these companies are going to get whatever moat they think they have eaten by Chat apps or open-sourced fine-tuned models.&lt;/p&gt;
&lt;p&gt;Here are some thoughts I have on pursuing fictional writing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/DavidAU&#34;&gt;models from David Belton aka DavidAU&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Maybe try the recent Qwen3 models since that&amp;rsquo;s the latest model?&lt;/li&gt;
&lt;li&gt;It seems like a PITA to deploy this myself, so if you want to use these models, I recommend trying to &lt;a href=&#34;#how-to-run-open-source-models&#34;&gt;run them locally&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/LocalLLaMA/comments/1hwvyze/comment/m64q0di/&#34;&gt;localllama comment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://eqbench.com/creative_writing.html&#34;&gt;creative writing benchmark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;white-collar-workers&#34; &gt;White Collar Workers
&lt;span&gt;
    &lt;a href=&#34;#white-collar-workers&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tryshortcut.ai/&#34;&gt;Shortcut - A better Excel co-pilot&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;other-ai-apps&#34; &gt;Other AI Apps
&lt;span&gt;
    &lt;a href=&#34;#other-ai-apps&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://glif.app/glifs&#34;&gt;Glif&lt;/a&gt;: A platform to build and use mini AI apps&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/models&#34;&gt;Explore Hugging Face models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dabit3/openai-functions-god-app&#34;&gt;Sample Multi-modal project using GPT4&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;You could probably use this as a base project and combine with other tools and models to make something better.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ILikeAI/AlwaysReddy&#34;&gt;LLM voice assistant project&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;This project allows you to vocally converse with an LLM. It also has some functional capabilities like reading/writing to clipboard.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-else-can-you-accomplish-with-ai&#34; &gt;What else can you accomplish with AI?
&lt;span&gt;
    &lt;a href=&#34;#what-else-can-you-accomplish-with-ai&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;Convert line art out of an uploaded sketch + colorize with Gemini&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;convert sketches to line art and colorize them &lt;a href=&#34;https://t.co/TfNHCaLP0D&#34;&gt;https://t.co/TfNHCaLP0D&lt;/a&gt; &lt;a href=&#34;https://t.co/qKy8RvuGuV&#34;&gt;pic.twitter.com/qKy8RvuGuV&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dreaming Tulpa  (@dreamingtulpa) &lt;a href=&#34;https://twitter.com/dreamingtulpa/status/1901571311622918454?ref_src=twsrc%5Etfw&#34;&gt;March 17, 2025&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;Extracting a professional shot product from a picture&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;tr&#34; dir=&#34;ltr&#34;&gt;insane insane insane &lt;a href=&#34;https://t.co/BcmihUNeJY&#34;&gt;pic.twitter.com/BcmihUNeJY&lt;/a&gt;&lt;/p&gt;&amp;mdash; nic (@nicdunz) &lt;a href=&#34;https://twitter.com/nicdunz/status/1901387475555090500?ref_src=twsrc%5Etfw&#34;&gt;March 16, 2025&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;Combining a product with a picture of a human (which could also be AI generated) for marketing or e-commerce shots. You can also do virtual try ons.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;You guys should try this: Gemini 2.0 Flash Experimental&lt;br&gt; &lt;a href=&#34;https://t.co/crjgDUKuTq&#34;&gt;pic.twitter.com/crjgDUKuTq&lt;/a&gt;&lt;/p&gt;&amp;mdash; Kurawa Dono (@KurawaDono) &lt;a href=&#34;https://twitter.com/KurawaDono/status/1900074784127672614?ref_src=twsrc%5Etfw&#34;&gt;March 13, 2025&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Alright, Google really killed it here.&lt;br&gt;&lt;br&gt;You can easily swap your garment just by uploading the pieces to Gemini Flash 2.0 and telling it what to do. &lt;a href=&#34;https://t.co/pNPBkIdRqy&#34;&gt;pic.twitter.com/pNPBkIdRqy&lt;/a&gt;&lt;/p&gt;&amp;mdash; Halim Alrasihi (@HalimAlrasihi) &lt;a href=&#34;https://twitter.com/HalimAlrasihi/status/1900667639086673962?ref_src=twsrc%5Etfw&#34;&gt;March 14, 2025&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;Creating a pixel sprite using &lt;a href=&#34;https://glif.app/@EgadZoundsGadzooks/glifs/clwpvrsfy000713x1hpl2rsg3&#34;&gt;Glif Sprite Generator&lt;/a&gt;, and then turning it into concept art using Gemini&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;next level. &lt;br&gt;&lt;br&gt;Pixel Sprite Character -&amp;gt; In Game Concept Art.&lt;br&gt;&lt;br&gt;everything is computer. &lt;a href=&#34;https://t.co/h1q4DQ0Ec6&#34;&gt;pic.twitter.com/h1q4DQ0Ec6&lt;/a&gt;&lt;/p&gt;&amp;mdash; Miguel | AP (@angrypenguinPNG) &lt;a href=&#34;https://twitter.com/angrypenguinPNG/status/1900303337318498792?ref_src=twsrc%5Etfw&#34;&gt;March 13, 2025&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;Creating gif animations using Gemini&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Gemini can generate pretty consistent gif animations too:&lt;br&gt;&lt;br&gt;&amp;#39;Create an animation by generating multiple frames, showing a seed growing into a plant and then blooming into a flower, in a pixel art style&amp;#39; &lt;a href=&#34;https://t.co/hbVTXEj5XZ&#34;&gt;pic.twitter.com/hbVTXEj5XZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Cristian Peas  (@ilumine_ai) &lt;a href=&#34;https://twitter.com/ilumine_ai/status/1900041501624971601?ref_src=twsrc%5Etfw&#34;&gt;March 13, 2025&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;Interior decoration&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;You can now design your house with AI.&lt;br&gt;&lt;br&gt;I asked Google Gemini &amp;quot;make the furniture go away&amp;quot; and then &amp;quot;decorate it with a modern chic aesthetic&amp;quot;. It did it on the first try.&lt;br&gt;&lt;br&gt;An interior designer would have charged $510k for this in the US. You can get infinite reps for free. &lt;a href=&#34;https://t.co/Tiv6TjuAyl&#34;&gt;pic.twitter.com/Tiv6TjuAyl&lt;/a&gt;&lt;/p&gt;&amp;mdash; Deedy (@deedydas) &lt;a href=&#34;https://twitter.com/deedydas/status/1900750406084686181?ref_src=twsrc%5Etfw&#34;&gt;March 15, 2025&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;h2 id=&#34;ai-research&#34; &gt;AI Research
&lt;span&gt;
    &lt;a href=&#34;#ai-research&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;h2 id=&#34;local-ai-models&#34; &gt;Local AI Models
&lt;span&gt;
    &lt;a href=&#34;#local-ai-models&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;The best aggregate about open-source LLMs is &lt;a href=&#34;https://www.reddit.com/r/LocalLLaMA/&#34;&gt;r/LocalLLaMA&lt;/a&gt;. However, it should be noted there is a base knowledge expectations required. I&amp;rsquo;ll go over it briefly.&lt;/p&gt;
&lt;h3 id=&#34;how-to-run-open-source-models&#34; &gt;How to Run Open-Source Models
&lt;span&gt;
    &lt;a href=&#34;#how-to-run-open-source-models&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;This section comes first because it&amp;rsquo;s derived from the resources in the rest of this page. The models you will be able to download will be limited by your RAM. To run a model locally, you may need &lt;a href=&#34;#ai-hardware&#34;&gt;hardware&lt;/a&gt;. Next, pick an open-source model based on the &lt;a href=&#34;#benchmarks&#34;&gt;benchmark&lt;/a&gt; closest to the task you want. In &lt;a href=&#34;https://lmstudio.ai/&#34;&gt;LM Studio&lt;/a&gt;, search for the model, and &lt;a href=&#34;https://blog.elijahlopez.ca/posts/how-to-pick-an-llm-quantization/&#34;&gt;choose a quantization&lt;/a&gt; to download.&lt;/p&gt;
&lt;p&gt;Once you&amp;rsquo;ve downloaded models, you can load them in LM Studio, select a system prompt, and continue. You can also start a server and integrate with local apps that are ollama compatible.&lt;/p&gt;
&lt;h3 id=&#34;open-source-interfaces&#34; &gt;Open-Source Interfaces
&lt;span&gt;
    &lt;a href=&#34;#open-source-interfaces&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;An interface is something that interacts with the model, but not the model itself. I know of a few.&lt;/p&gt;
&lt;h3 id=&#34;interfaces&#34; &gt;Interfaces
&lt;span&gt;
    &lt;a href=&#34;#interfaces&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://lmstudio.ai/&#34;&gt;LM Studio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jan.ai/&#34;&gt;Jan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://comfyui-wiki.com/&#34;&gt;ComfyUI&lt;/a&gt;: diffusion (media) model GUI&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/open-webui/open-webui&#34;&gt;openwebui&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/oobabooga/text-generation-webui&#34;&gt;text-generation-webui&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;Stable Diffusion web UI&lt;/a&gt;&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of these require &amp;ldquo;backends&amp;rdquo; which all come from llama.cpp or kobold.cpp. However, &lt;a href=&#34;https://github.com/ollama/ollama&#34;&gt;Ollama&lt;/a&gt; is super simple for running models.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.reddit.com/r/LocalLLaMA/comments/1ki7tg7/dont_offload_gguf_layers_offload_tensors_200_gen/&#34;&gt;Offload Tensors for Performance Improvements&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This post is very new and talks about how even with less than the recommended hardware requirements, you can still improve throughput by being selective about what is offloaded to the GPU. It seems that some tensors like FPN tensors happen to be very large and use basic matrix multiplication which can be done efficiently on the CPU, whereas small tensors like attention tensors benefit from GPU parallelization! It&amp;rsquo;s a breakthrough innovation in my opinion. Original credit goes to  &lt;a href=&#34;https://www.reddit.com/user/EmilPi/&#34;&gt;u/EmilPi&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;learning&#34; &gt;Learning
&lt;span&gt;
    &lt;a href=&#34;#learning&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;Using AI&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/whitepaper-prompt-engineering&#34;&gt;Prompt Engineering&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Building with AI&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/generative-ai-for-beginners&#34;&gt;21 Lessons, Get Started Building with Generative AI&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Researcher-oriented&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://neuralnetworksanddeeplearning.com/index.html&#34;&gt;Neural Networks and Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf&#34;&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;pytorch&lt;/li&gt;
&lt;li&gt;tensor&lt;/li&gt;
&lt;li&gt;llama.cpp&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://x.com/MaximeRivest/status/1929861781448536081?t=HmwYmLifYq1QJhSKavjL3g&#34;&gt;A simple introduction to DSPy&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;read-frontier-papers&#34; &gt;Read Frontier Papers
&lt;span&gt;
    &lt;a href=&#34;#read-frontier-papers&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;One of the most eye opening things my friend told me is that there is practical benefit to reading frontier research articles. In his case it was related to algorithmic trading, but I&amp;rsquo;m going to go further and suggest that it applies to all areas of frontier development. Whether that be quant finance, AI research, cancer research. There is merit in spending time on reading research if you are able to utilize new information readily.&lt;/p&gt;
&lt;h3 id=&#34;follow-ai-researchers&#34; &gt;Follow AI Researchers
&lt;span&gt;
    &lt;a href=&#34;#follow-ai-researchers&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;They will talk about new things they may have learned or how to break in, or tweet out an article, etc.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/yann-lecun/recent-activity/all/&#34;&gt;Yann Lecunn&lt;/a&gt; - VP &amp;amp; Chief AI Scientist At Meta&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://x.com/AndrewYNg&#34;&gt;Andrew Ng&lt;/a&gt; - previously head of Baidu AI and Google Brain&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://x.com/karpathy&#34;&gt;Andrej Karpathy&lt;/a&gt; - founding team @ OpenAI&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://x.com/demishassabis&#34;&gt;Demis Hassabis&lt;/a&gt; - Co-Founder &amp;amp; CEO @GoogleDeepMind&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://x.com/fchollet&#34;&gt;Franois Chollet&lt;/a&gt; - creator of ARC-AGI benchmark&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;get-resources&#34; &gt;Get Resources
&lt;span&gt;
    &lt;a href=&#34;#get-resources&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;The easiest way to get resources is to get MONEY. To get MONEY, you need a JOB. It&amp;rsquo;s probably easier to &lt;a href=&#34;#ai-research-companies&#34;&gt;GET A JOB&lt;/a&gt; than to already have the money necessarily to buy &lt;a href=&#34;#ai-hardware&#34;&gt;hardware&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;ai-research-companies&#34; &gt;AI Research Companies
&lt;span&gt;
    &lt;a href=&#34;#ai-research-companies&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Company&lt;/th&gt;
          &lt;th&gt;Based&lt;/th&gt;
          &lt;th&gt;Notes&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://jobs.ashbyhq.com/cohere&#34;&gt;Cohere&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Canada/USA&lt;/td&gt;
          &lt;td&gt;Command R model&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://openai.com/careers/&#34;&gt;Open AI&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;USA&lt;/td&gt;
          &lt;td&gt;The creator of ChatGPT, led by &lt;a href=&#34;https://en.wikipedia.org/wiki/Sam_Altman&#34;&gt;Sam Altman&lt;/a&gt; (disclosure, I&amp;rsquo;m biased against Altman)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://deepmind.google/about/careers/&#34;&gt;Google DeepMind&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;USA&lt;/td&gt;
          &lt;td&gt;They came out with the original Transformer research that OpenAI used successfully and work on Gemini and Gemma&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://x.ai/careers/open-roles&#34;&gt;xAI&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;USA&lt;/td&gt;
          &lt;td&gt;Creator of grok, very integrated with X, owned by Elon Musk&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.metacareers.com/&#34;&gt;Meta AI&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Anywhere&lt;/td&gt;
          &lt;td&gt;Creators of LLaMA&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.nvidia.com/en-us/about-nvidia/careers/&#34;&gt;NVIDIA&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;USA&lt;/td&gt;
          &lt;td&gt;Manufacturer of the best &lt;em&gt;commercially available&lt;/em&gt; GPUs for training AI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.anthropic.com/jobs&#34;&gt;Anthropic&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;USA&lt;/td&gt;
          &lt;td&gt;Claude&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://ssi.inc/&#34;&gt;Safe Superintelligence Inc.&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Palo Alto, Tel Aviv&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Ilya_Sutskever&#34;&gt;Ilya Sutskever&lt;/a&gt; former OpenAI Chief Scientist &amp;amp; Co-founder&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://thinkingmachines.ai/&#34;&gt;Thinking Machines Lab&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;USA?&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Mira_Murati&#34;&gt;Mira Murati&lt;/a&gt; former Open AI CTO&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://ndea.com/&#34;&gt;Ndea&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;USA&lt;/td&gt;
          &lt;td&gt;intelligence science lab founded by X:@fchollet &amp;amp; X:@mikeknoop&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://vectorinstitute.ai/about/opportunities/open-positions-at-vector/&#34;&gt;Vector Institute&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Toronto, CA&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://apply.workable.com/mila-2/?lng=en&#34;&gt;Mila&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Quebec&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://allenai.org/careers&#34;&gt;Ai2&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Seattle, WA&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;ai-product-companies&#34; &gt;AI Product Companies
&lt;span&gt;
    &lt;a href=&#34;#ai-product-companies&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;h2 id=&#34;ai-hardware&#34; &gt;AI Hardware
&lt;span&gt;
    &lt;a href=&#34;#ai-hardware&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;NVIDIA Tensor Core GPUs: enterprise&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.itsalltruffles.com/&#34;&gt;Truffle&lt;/a&gt;: end-customer hardware for running models locally&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;jargon&#34; &gt;Jargon
&lt;span&gt;
    &lt;a href=&#34;#jargon&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;AI: Artificial Intelligence&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=T-D1OfcDW1M&amp;amp;pp=ygUDUkFH&#34;&gt;RAG: Retrieval-Augmented Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Fine-Tuning&lt;/li&gt;
&lt;li&gt;LLM: Large Language Model&lt;/li&gt;
&lt;li&gt;LLaMA : Large Language Model Meta AI&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/HyzlYwjoXOQ?si=r1cFI6E8lf5DX9RX&#34;&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Inference&lt;/li&gt;
&lt;li&gt;Segment&lt;/li&gt;
&lt;li&gt;Tokens&lt;/li&gt;
&lt;li&gt;NGMI: not going to make it&lt;/li&gt;
&lt;li&gt;SOTA: State of the art&lt;/li&gt;
&lt;li&gt;LoRA: Low-Rank Adaptation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;final-words&#34; &gt;Final Words
&lt;span&gt;
    &lt;a href=&#34;#final-words&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;There are a lot of variety of tools, models, and research. There&amp;rsquo;s an opportunity to capitalize on research, combine multiple models, and provide an offering that is SOTA. If you&amp;rsquo;re unemployed, you should seize on this opportunity. VC appetite is high for AI-related companies, and competition is very hot.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AI SimpleQA Leaderboard</title>
      <link>https://blog.elijahlopez.ca/posts/ai-simpleqa-leaderboard/</link>
      <pubDate>Fri, 02 May 2025 18:50:57 -0400</pubDate>
      
      <guid>https://blog.elijahlopez.ca/posts/ai-simpleqa-leaderboard/</guid>
      <description>&lt;h3 id=&#34;benchmark-descriptions&#34; &gt;Benchmark Descriptions
&lt;span&gt;
    &lt;a href=&#34;#benchmark-descriptions&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;&lt;a href=&#34;https://openai.com/index/introducing-simpleqa/&#34;&gt;SimpleQA&lt;/a&gt; is a benchmark to grade the factuality of an LLM. I wrote this post because while writing my &lt;del&gt;upcoming&lt;/del&gt; &lt;a href=&#34;https://blog.elijahlopez.ca/posts/ai&#34;&gt;AI Awesome List&lt;/a&gt;, I realized there was no readily available webpage indexed by Google showing a leaderboard for SimpleQA.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s now September, and I am demanding a better benchmark. Personally I think asking AI research based questions with shorter answers is a good start. For example, when asking AI about best housing policies, it likes to shotgun answer you instead of succinctly stating that the best housing policies are upzoning and speeding up permitting. Of course, I disagree and personally I believe restoring foreign capital and cutting taxes such as HST/GST for all primary home buyers, and cutting developer charges are the most effective policies to implement today.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.linkup.so/blog/linkup-establishes-sota-performance-on-simpleqa&#34;&gt;Linkup&lt;/a&gt; had this to say about factuality:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Our evaluations show that, when it comes to factuality, internet connectivity is more important than model size.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;AIME&#39;25 leaderboard: Math&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve removed Chatbot Arena and ArenaHard as DeepSeek R1 05/28 is really good at following instructions and sets the expectations fairly high. Instead I&amp;rsquo;ve added Humanity&amp;rsquo;s Last Exam.&lt;/p&gt;
&lt;p&gt;Before reading this table, please take note of OpenAI&amp;rsquo;s comment regarding that the grading rubric itself cannot handle thorough exploration. My takeaway is that scores above 90% cannot be compared with each other.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ChatGPT agent scores lower on SimpleQA accuracy than o3 did. Manual investigation revealed cases where ChatGPT agents more thorough approach to research surfaced potential flaws in our grading rubric that were not apparent to o3, such as instances in which Wikipedia may contain inaccurate information. We are considering updates to this evaluation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Model / Product&lt;/th&gt;
          &lt;th&gt;Company&lt;/th&gt;
          &lt;th&gt;Tier&lt;/th&gt;
          &lt;th&gt;SimpleQA&lt;/th&gt;
          &lt;th&gt;AIME&#39;25&lt;/th&gt;
          &lt;th&gt;Humanity&amp;rsquo;s Last Exam&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek-V3.2-Exp w/tool &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;97.1%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek-V3.1-Terminus w/tool&lt;sup id=&#34;fnref1:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;96.8%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;Sep-2025&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://getliner.com/&#34;&gt;Liner Pro Reasoning&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://liner.com/&#34;&gt;Liner&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://liner.com/learn/deep-research-comparison&#34;&gt;95.30&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://exa.ai/&#34;&gt;Exa Research Pro&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Exa&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://exa.ai/blog/introducing-exa-research&#34;&gt;94.9%&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Perplexity Deep Research&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.perplexity.ai/&#34;&gt;Perplexity&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;93.90&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Liner Pro&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://liner.com/&#34;&gt;Liner&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://liner.com/learn/liner-accurate-ai-search&#34;&gt;93.70&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://brave.com/search/api/&#34;&gt;Brave Multiple Searches&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Brave&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://brave.com/blog/ai-grounding/&#34;&gt;93.25&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://exa.ai/&#34;&gt;Exa Research&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Exa&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://exa.ai/blog/introducing-exa-research&#34;&gt;91.6%&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://openai.com/index/chatgpt-agent-system-card/&#34;&gt;ChatGPT Agent System Card&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;91.4%&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://openai.com/index/chatgpt-agent-system-card/&#34;&gt;o3 with browsing&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;95.4% (read note)&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://brave.com/search/api/&#34;&gt;Brave Single Search&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Brave Search&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://brave.com/blog/ai-grounding/&#34;&gt;90.78&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Perplexity Pro&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.perplexity.ai/&#34;&gt;Perplexity&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;90.60&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://brave.com/search/api/&#34;&gt;Brave Single Search + Reasoning&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Brave Search&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://brave.com/blog/ai-grounding/&#34;&gt;90.5&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://www.linkup.so/&#34;&gt;Linkup Web Search&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Linkup&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;90.10&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2503.20201&#34;&gt;ODS-v2+DeepSeek-R1&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Open Deep Search&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;88.3%&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Perplexity Sonar Pro&lt;/td&gt;
          &lt;td&gt;Perplexity&lt;/td&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;85.80&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
          &lt;td&gt;N/A&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude-4-Opus&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;75.5%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ChatGPT-4.5&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;62.50&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://openai.com/index/gpt-5-system-card/&#34;&gt;ChatGPT-5-thinking&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;55%&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;50&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemini-2.5-Pro&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;54.00&lt;/td&gt;
          &lt;td&gt;86.70&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude-3.7-Sonnet&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;50.00&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;59.8&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;o3&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;49.4&lt;/td&gt;
          &lt;td&gt;88.9&lt;/td&gt;
          &lt;td&gt;85.9&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Grok 3&lt;/td&gt;
          &lt;td&gt;xAI&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;44.60&lt;/td&gt;
          &lt;td&gt;93.3&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;o1&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;42.60&lt;/td&gt;
          &lt;td&gt;79.20&lt;/td&gt;
          &lt;td&gt;61&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ChatGPT-4.1&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;41.60&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;50&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ChatGPT-4o&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;39.00&lt;/td&gt;
          &lt;td&gt;14.00&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Kimi K2&lt;/td&gt;
          &lt;td&gt;Moonshot AI&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;31.0&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek-R1 (01/20)&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;30.10&lt;/td&gt;
          &lt;td&gt;70.00&lt;/td&gt;
          &lt;td&gt;8.5&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek-R1 (05/28)&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;27.80&lt;/td&gt;
          &lt;td&gt;87.50&lt;/td&gt;
          &lt;td&gt;17.7&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek-R1-0528-Qwen3-8B&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;76.3&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemini-2.5-Flash&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;IV&lt;/td&gt;
          &lt;td&gt;29.90&lt;/td&gt;
          &lt;td&gt;78.00&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Claude-3.5-Sonnet&lt;/td&gt;
          &lt;td&gt;Anthropic&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;28.4&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;33&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepSeek-V3&lt;/td&gt;
          &lt;td&gt;DeepSeek&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;24.9&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;o4-mini&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;20.20&lt;/td&gt;
          &lt;td&gt;92.70&lt;/td&gt;
          &lt;td&gt;79.1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;o3-mini&lt;/td&gt;
          &lt;td&gt;OpenAI&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;13.80&lt;/td&gt;
          &lt;td&gt;86.5&lt;/td&gt;
          &lt;td&gt;66.1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-235B-A22B&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;15.00&lt;/td&gt;
          &lt;td&gt;81.5&lt;/td&gt;
          &lt;td&gt;95.6&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemma 3 27B&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;10.00&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemma 2 27B&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;9.20&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-32B (Dense)&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;8.00&lt;/td&gt;
          &lt;td&gt;72.9&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-30B-A3B (MoE)&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;8.00&lt;/td&gt;
          &lt;td&gt;70.9&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;EXAONE-Deep-32B&lt;/td&gt;
          &lt;td&gt;LG&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;80&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-14B&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;EXAONE-Deep-7.8B&lt;/td&gt;
          &lt;td&gt;LG&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;76.7&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3-8B&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;EXAONE-Deep-2.4B&lt;/td&gt;
          &lt;td&gt;LG&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;73.3&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Apriel-Nemotron-15B-Thinker&lt;/td&gt;
          &lt;td&gt;NVIDIA / SERVICE NOW&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;60.0&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemma 3 12B&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;6.30&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemma 3n&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemma 3 4B&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;III&lt;/td&gt;
          &lt;td&gt;4.00&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemma 2 9B&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;5.30&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Phi 4 Reasoning Plus&lt;/td&gt;
          &lt;td&gt;Microsoft&lt;/td&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;3.00&lt;/td&gt;
          &lt;td&gt;78.00&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemma 2 2B&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;III&lt;/td&gt;
          &lt;td&gt;2.80&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gemma 3 1B&lt;/td&gt;
          &lt;td&gt;Google&lt;/td&gt;
          &lt;td&gt;III&lt;/td&gt;
          &lt;td&gt;2.20&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Qwen3 4B&lt;/td&gt;
          &lt;td&gt;Qwen&lt;/td&gt;
          &lt;td&gt;III&lt;/td&gt;
          &lt;td&gt;1.00&lt;/td&gt;
          &lt;td&gt;65.6&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;notes&#34; &gt;Notes
&lt;span&gt;
    &lt;a href=&#34;#notes&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;Missing Models&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mistral Medium 3&lt;/li&gt;
&lt;li&gt;DeepSeek V3 03/24&lt;/li&gt;
&lt;li&gt;Google Gemini 2.5 Pro May update&lt;/li&gt;
&lt;li&gt;llama 4 models (e.g. Llama 4 Behemoth)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For Claude 4, there was no score available for SimpleQA, however someone tested Opus on a subset and it scored the highest.&lt;/p&gt;
&lt;h3 id=&#34;definition-of-tier&#34; &gt;Definition of Tier
&lt;span&gt;
    &lt;a href=&#34;#definition-of-tier&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Tier&lt;/th&gt;
          &lt;th&gt;Name&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;MI&lt;/td&gt;
          &lt;td&gt;Flagship Model&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;PI&lt;/td&gt;
          &lt;td&gt;Flagship Product&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;OI&lt;/td&gt;
          &lt;td&gt;Open-Weights&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;II&lt;/td&gt;
          &lt;td&gt;Consumer hardware&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;III&lt;/td&gt;
          &lt;td&gt;Edge hardware&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;IV&lt;/td&gt;
          &lt;td&gt;Speed&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;more-benchmarks&#34; &gt;More Benchmarks
&lt;span&gt;
    &lt;a href=&#34;#more-benchmarks&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;&lt;a href=&#34;https://www.swebench.com/#verified&#34;&gt;https://www.swebench.com/#verified&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lastexam.ai/&#34;&gt;https://lastexam.ai/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34; &gt;References
&lt;span&gt;
    &lt;a href=&#34;#references&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;&lt;a href=&#34;https://x.com/scaling01/status/1926017718286782643/photo/1&#34;&gt;https://x.com/scaling01/status/1926017718286782643/photo/1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/introducing-o3-and-o4-mini/&#34;&gt;https://openai.com/index/introducing-o3-and-o4-mini/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gr.inc/OpenAI/SimpleQA/&#34;&gt;https://gr.inc/OpenAI/SimpleQA/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://qwenlm.github.io/blog/qwen3/&#34;&gt;https://qwenlm.github.io/blog/qwen3/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://x.com/nathanhabib1011/status/1917230699582751157/photo/1&#34;&gt;https://x.com/nathanhabib1011/status/1917230699582751157/photo/1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openai/simple-evals/tree/main&#34;&gt;https://github.com/openai/simple-evals/tree/main&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://livecodebench.github.io/leaderboard.html&#34;&gt;https://livecodebench.github.io/leaderboard.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://deepmind.google/technologies/gemini/flash/&#34;&gt;https://deepmind.google/technologies/gemini/flash/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://matharena.ai/?utm_campaign=Data%20Points&amp;amp;utm_source=hs_email&amp;amp;utm_medium=email&#34;&gt;https://matharena.ai/?utm_campaign=Data%20Points&amp;amp;utm_source=hs_email&amp;amp;utm_medium=email&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/lmarena/arena-hard-auto?tab=readme-ov-file#leaderboard&#34;&gt;https://github.com/lmarena/arena-hard-auto?tab=readme-ov-file#leaderboard&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.vals.ai/benchmarks/aime-2025-03-11&#34;&gt;https://www.vals.ai/benchmarks/aime-2025-03-11&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/introducing-simpleqa/&#34;&gt;https://openai.com/index/introducing-simpleqa/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/microsoft/phi-4&#34;&gt;https://huggingface.co/microsoft/phi-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/&#34;&gt;https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://x.ai/news/grok-3&#34;&gt;https://x.ai/news/grok-3&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma&#34;&gt;Gemma&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kgruiz/Llama-4-Comps?tab=readme-ov-file&#34;&gt;Llama 4 Benchmark and Model Comparison Report&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/ServiceNow-AI/Apriel-Nemotron-15b-Thinker#evaluation&#34;&gt;Apriel-Nemotron-15b-Thinker &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2503.12524&#34;&gt;LG EXAONE Deep&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://brave.com/blog/ai-grounding/&#34;&gt;https://brave.com/blog/ai-grounding/&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://api-docs.deepseek.com/news/news250929&#34;&gt;Introducing DeepSeek-V3.2-Exp&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to Pick an LLM Quantization?</title>
      <link>https://blog.elijahlopez.ca/posts/which-quantization-to-choose-local-llm/</link>
      <pubDate>Thu, 04 Apr 2024 19:50:28 -0400</pubDate>
      
      <guid>https://blog.elijahlopez.ca/posts/which-quantization-to-choose-local-llm/</guid>
      <description>&lt;p&gt;Generally speaking, the more bits the better and L &amp;gt; M &amp;gt; S. Therefore, when choosing a model, pick the largest model that fits into your RAM. Your GPU can be used to &amp;ldquo;offload&amp;rdquo; layers of the model to the GPUand let the CPU handle the rest. Offloading to the GPU&amp;rsquo;s VRAM is important for a faster LLM. The only reason I wrote this blog post is because it takes too long to figure this out from online sources.&lt;/p&gt;
&lt;p&gt;When choosing the model size, make sure it&amp;rsquo;s at least 3GB smaller than your RAM size to leave space for other software you are running.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
